{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch torchvision pillow ipywidgets matplotlib numpy ipython\n",
    "#Version gpu: pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu117\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class PrepareDataSet(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, split=\"train\", scale_factor=4, patch_size=64, seed=42):\n",
    "        '''\n",
    "        Lee las imagenes png del dataset en el root_dir, divide el conjunto en un 80%\n",
    "        de entrenaimento y el 20% de validación.\n",
    "\n",
    "        Para cada imagen se tiene su versión en HR (High resolution) y LR(Low resolution)\n",
    "        El escalado esta diseñado para multiplicar por 4 la resolucion original.\n",
    "        El entrenamiento será así, si se quiere un escalado a 8, cambiar el parametro pero\n",
    "        requiere mas gpu y tiempo.\n",
    "\n",
    "        La semilla es simplemente para poder recrear un entrenamiento.\n",
    "        El patch_size es el tamaño en pixeles de cada parche HR (en este caso 64x64)\n",
    "        '''\n",
    "        self.root_dir = root_dir\n",
    "        self.scale = scale_factor\n",
    "        self.patch_size = patch_size\n",
    "        self.lr_patch = patch_size // scale_factor\n",
    "        \n",
    "        all_files = sorted([f for f in os.listdir(root_dir) if f.endswith(\".png\")])\n",
    "        random.seed(seed)\n",
    "        random.shuffle(all_files) #Para aleatoriedad en el entrenamiento y validacion\n",
    "        split_index = int(0.8 * len(all_files))\n",
    "\n",
    "        if split == \"train\":\n",
    "            self.file_list = all_files[:split_index]\n",
    "        else:\n",
    "            self.file_list = all_files[split_index:]\n",
    "\n",
    "        #Toma un recorte aleatorio del mataño patch_size x patch_size (64x64) de la imagen HR completa\n",
    "        self.hr_transform = transforms.Compose([transforms.RandomCrop(patch_size),transforms.ToTensor()])\n",
    "\n",
    "        #Redimensiona bicubicamente el parche HR recortaso a un parche LR de lr_patch x lr_patch (16 x 16)\n",
    "        self.lr_transform = transforms.Compose([transforms.Resize(self.lr_patch, interpolation=Image.BICUBIC), transforms.ToTensor()])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx): #No se usa explicitamente pero es ocupado para iterar sobre el dataset\n",
    "        '''\n",
    "        Encuentra la imagen en el dataset dado idx, toma un corte aleatorio de patch_size x patch_size, se guarda en hr,\n",
    "        y del anterior hr se genera su version en lr, guardandolo en lr.\n",
    "\n",
    "        Retorna:\n",
    "            Un diccionario con dos claves:\n",
    "\n",
    "            \"lr\": tensor de baja resolución ([3, lr_patch, lr_patch]).\n",
    "\n",
    "            \"hr\": tensor de alta resolución ([3, patch_size, patch_size]).\n",
    "        '''\n",
    "        img_name = self.file_list[idx]\n",
    "        hr_path = os.path.join(self.root_dir, img_name)\n",
    "        hr_image = Image.open(hr_path).convert(\"RGB\") #necesitamos rgn\n",
    "        \n",
    "        hr_patch = self.hr_transform(hr_image)\n",
    "        lr_patch = self.lr_transform(transforms.ToPILImage()(hr_patch))\n",
    "        \n",
    "        return {\"lr\": lr_patch, \"hr\": hr_patch}\n",
    "\n",
    "#Lectura, carga y preparacion del dataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset_root = \"Flickr2K\"\n",
    "\n",
    "train_dataset = PrepareDataSet(root_dir=dataset_root, split=\"train\", scale_factor=4, patch_size=128)\n",
    "val_dataset   = PrepareDataSet(root_dir=dataset_root, split=\"val\",   scale_factor=4, patch_size=128)\n",
    "\n",
    "#Ajustar el batch_size dependiendo de la gpu, el mio con 10 ya ocupa toda la VRAM de la gpu\n",
    "#El numero de workers afecta a la cpu, tengo 8 nuecleos, asi que pongo 4 workers\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True,  num_workers=4, pin_memory=True) # en entrenamiento mezclar el orden de los parches cada epoca nueva\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=10, shuffle=False, num_workers=4, pin_memory=True) #pin memory true pues  hago uso de gpu, tenerlo en true usando cpu no tiene mucho sentido\n",
    "\n",
    "batch = next(iter(train_loader)) #toma el siguiente mini batch del train loader\n",
    "lr_batch = batch[\"lr\"].to(device, non_blocking=True) #[10, 3, 32, 32]\n",
    "hr_batch = batch[\"hr\"].to(device, non_blocking=True) #[10, 3, 128, 128]\n",
    "\n",
    "#print(\"LR tamaño de batch:\", lr_batch.shape, \"Device:\")\n",
    "#print(\"HR tamaño de batch:\", hr_batch.shape, \"Device:\")\n",
    "print(\"Device: \", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/bash: line 1: [Estructura: command not found\n"
     ]
    }
   ],
   "source": [
    "![Estructura RRDB]{./resources/RRDB.png}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualDenseBlock(nn.Module):\n",
    "    def __init__(self, in_channels, growth_channels=32):\n",
    "        '''\n",
    "        Realiza 5 convoluciones en cadena, todos con un kernel de 3x3, stride de 1, y padding de 1.\n",
    "        Parametros:\n",
    "            grow_channels: cuantos filtros produce cada convolucion\n",
    "            in_channels: numero de canales por entrada\n",
    "        '''\n",
    "        super(ResidualDenseBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, growth_channels, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(in_channels + growth_channels, growth_channels, 3, 1, 1) #recibe concatenacion de entrada original + salida de conv1\n",
    "        self.conv3 = nn.Conv2d(in_channels + 2*growth_channels, growth_channels, 3, 1, 1) #recibe entrada original + salida de conv2, etc.\n",
    "        self.conv4 = nn.Conv2d(in_channels + 3*growth_channels, growth_channels, 3, 1, 1)\n",
    "        self.conv5 = nn.Conv2d(in_channels + 4*growth_channels, in_channels, 3, 1, 1)\n",
    "        self.lrelu = nn.LeakyReLU(0.2, inplace=True) #Funcion de activacion\n",
    "        self.scale = 0.2 #Estabilizar el entrenamiento, para que la contribucion sea proporcional a la escala\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Realiza las convoluciones y les aplica la funcion de acticacion\n",
    "        '''\n",
    "        inputs = x\n",
    "        x1 = self.lrelu(self.conv1(inputs))\n",
    "        x2 = self.lrelu(self.conv2(torch.cat([inputs, x1], dim=1))) #FUncion cat concatena inputs con x1, analogo para las lineas de abajo\n",
    "        x3 = self.lrelu(self.conv3(torch.cat([inputs, x1, x2], dim=1)))\n",
    "        x4 = self.lrelu(self.conv4(torch.cat([inputs, x1, x2, x3], dim=1)))\n",
    "        x5 = self.conv5(torch.cat([inputs, x1, x2, x3, x4], dim=1))\n",
    "        return inputs + x5 * self.scale\n",
    "\n",
    "class RRDB(nn.Module):\n",
    "    '''\n",
    "    Agrupa 3 ResidualDenseBlock en serie.\n",
    "    '''\n",
    "    def __init__(self, in_channels, growth_channels=32):\n",
    "        super(RRDB, self).__init__()\n",
    "        self.rdb1 = ResidualDenseBlock(in_channels, growth_channels)\n",
    "        self.rdb2 = ResidualDenseBlock(in_channels, growth_channels)\n",
    "        self.rdb3 = ResidualDenseBlock(in_channels, growth_channels)\n",
    "        self.scale = 0.2\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.rdb1(x)\n",
    "        out = self.rdb2(out)\n",
    "        out = self.rdb3(out)\n",
    "        return x + out * self.scale\n",
    "\n",
    "class RRDBNet(nn.Module):\n",
    "    '''\n",
    "    Red de super‐resolución, Funciona como generador en ESRGAN, aumentando la resolución \n",
    "    de la imagen de entrada por un factor scale.\n",
    "\n",
    "    '''\n",
    "    def __init__(self, in_channels=3, out_channels=3, num_features=64, growth_channels=32, num_blocks=23, scale=4):\n",
    "        '''\n",
    "         Parámetros:\n",
    "                in_channels : Canales de la imagen de entrada (3 para RGB).\n",
    "                out_channels : Canales de la imagen de salida (3 para RGB).\n",
    "                num_features : Número de filtros en la capa inicial y en cada bloque RRDB.\n",
    "                num_blocks : Número de bloques RRDB que componen la “trunk” (p. ej. 23). #El trunk es la red que agrupa los bloques RRDB\n",
    "                scale : Factor de aumento de resolución.\n",
    "        '''\n",
    "        super(RRDBNet, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.conv_first = nn.Conv2d(in_channels, num_features, 3, 1, 1)\n",
    "        \n",
    "        rrdb_blocks = []\n",
    "        for _ in range(num_blocks):\n",
    "            rrdb_blocks.append(RRDB(num_features, growth_channels))\n",
    "        self.rrdb_trunk = nn.Sequential(*rrdb_blocks) #Desempaquetarlos en una lista, EJ: capas = [capa0, capa1, capa2], ent nn.Sequential(*capas) = nn.Sequential(capas[0], capas[1], capas[2])\n",
    "        self.trunk_conv = nn.Conv2d(num_features, num_features, 3, 1, 1)\n",
    "        \n",
    "\n",
    "        #subidas de resolucion\n",
    "        upsampling_layers = []\n",
    "        for _ in range(int(torch.log2(torch.tensor(scale)).item())): #Log2 para ver que tantas iteraciones se hace, si scale igual a 4, entonces log2 de 4 es 2, se harán 2 iteraciones\n",
    "            upsampling_layers += [\n",
    "                nn.Conv2d(num_features, num_features * 4, 3, 1, 1), #kernel=3, stride 1, padding 1.\n",
    "                nn.PixelShuffle(2),\n",
    "                nn.LeakyReLU(0.2, inplace=True)\n",
    "            ]\n",
    "        self.upsampling = nn.Sequential(*upsampling_layers) #Lista con todas las capas en orden [conv2d, pixelShuffle, leakyRelu, ...] se repiten los 3 log2 veces\n",
    "\n",
    "        # Final convs\n",
    "        self.conv_last = nn.Conv2d(num_features, num_features, 3, 1, 1)\n",
    "        self.conv_out = nn.Conv2d(num_features, out_channels, 3, 1, 1)\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        fea = self.conv_first(x)\n",
    "        trunk = self.trunk_conv(self.rrdb_trunk(fea))\n",
    "        fea = fea + trunk\n",
    "        fea = self.upsampling(fea)\n",
    "        out = self.lrelu(self.conv_last(fea))\n",
    "        out = self.conv_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    '''\n",
    "    Esta clase implementa un discriminador que analiza parches de la imagen de alta resolución\n",
    "    y produce un mapa de salida indicando la probabilidad de “realismo” para cada\n",
    "    región. \n",
    "\n",
    "    Supongamos que pasamos una imagel real (HR) por el discriminador, obtenemos el siguiente tensor\n",
    "    antes de aplicar sigmoid:\n",
    "\n",
    "    [[ 2.0,   0.5 ],\n",
    "     [ -1.0,  1.0 ]]\n",
    "\n",
    "     Es un mapa de 2x2.\n",
    "\n",
    "     Igualmente al pasar la imagen generada (fake) por el discriminador se produce otro mapa 2x2:\n",
    "\n",
    "     [[ -0.5,  -1.0 ],\n",
    "    [  0.2,  -2.0 ]]\n",
    "\n",
    "    El objetivo del discriminador es convertir los logits en probabilidades y comparar con las etiquetas\n",
    "    (1 para real, 0 para fake)\n",
    "\n",
    "    Al aplicar sigmoid al real se devuelve:\n",
    "\n",
    "    [[ 0.8808,  0.6225 ],\n",
    "      [ 0.2689,  0.7311 ]]\n",
    "\n",
    "      Cercanos a 1, son reales, \n",
    "\n",
    "      Para la imagen fake:\n",
    "\n",
    "      [[ 0.3775,  0.2689 ],\n",
    "      [ 0.5498,  0.1192 ]]\n",
    "\n",
    "      Hay uno con 54% de ser real, lo cual es falso, pues es la imagen fake\n",
    "\n",
    "\n",
    "      Nota: aqui no se aplica sigmoide ni el BCEWithLogitLoss, es hasta el entrenamiento.\n",
    "    '''\n",
    "    def __init__(self, in_channels=3, base_channels=64):\n",
    "        '''\n",
    "        in_channels : Número de canales en la imagen de entrada (normalmente 3 para RGB).\n",
    "        base_channels: Número de filtros en la primera capa convolucional; las capas \n",
    "                        posteriores amplían este número progresivamente.\n",
    "        '''\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        #Conv 3x3, stide 1, padding 1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, base_channels, 3, 1, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels, base_channels, 4, 2, 1),\n",
    "            nn.BatchNorm2d(base_channels), #batch para cada mini batch calcula la media y varainza de las activaaciones y normaliza a media cero.\n",
    "            nn.LeakyReLU(0.2, inplace=True) #Despues de normalizar leaky relu para considerar tanto positivos como negativos\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels, base_channels * 2, 3, 1, 1),\n",
    "            nn.BatchNorm2d(base_channels * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels * 2, base_channels * 2, 4, 2, 1),\n",
    "            nn.BatchNorm2d(base_channels * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels * 2, base_channels * 4, 3, 1, 1),\n",
    "            nn.BatchNorm2d(base_channels * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels * 4, base_channels * 4, 4, 2, 1),\n",
    "            nn.BatchNorm2d(base_channels * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels * 4, base_channels * 8, 3, 1, 1),\n",
    "            nn.BatchNorm2d(base_channels * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels * 8, base_channels * 8, 4, 2, 1),\n",
    "            nn.BatchNorm2d(base_channels * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.conv9 = nn.Conv2d(base_channels * 8, 1, 3, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)   # [B, 64, H, W]\n",
    "        x = self.layer2(x)   # [B, 64, H/2, W/2]\n",
    "        x = self.layer3(x)   # [B, 128, H/2, W/2]\n",
    "        x = self.layer4(x)   # [B, 128, H/4, W/4]\n",
    "        x = self.layer5(x)   # [B, 256, H/4, W/4]\n",
    "        x = self.layer6(x)   # [B, 256, H/8, W/8]\n",
    "        x = self.layer7(x)   # [B, 512, H/8, W/8]\n",
    "        x = self.layer8(x)   # [B, 512, H/16, W/16]\n",
    "        out = self.conv9(x)  # [B, 1, H/16, W/16]\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGFeatureExtractor(nn.Module):\n",
    "    '''\n",
    "    En conjunto, este código prepara un módulo que toma una imagen de entrada, \n",
    "    la normaliza de ser necesario y la pasa por la VGG19, devolviendo los mapas \n",
    "    de características en los índices indicados por layer_ids.\n",
    "    \n",
    "    Esos mapas se usarán para calcular la pérdida perceptual comparando \n",
    "    características de la imagen generada con las de la imagen real.\n",
    "    '''\n",
    "    def __init__(self, layer_ids=[35], use_input_norm=True):\n",
    "        \"\"\"\n",
    "        layer_ids: índices de capas cuyas salidas se usarán (p.ej., capa 35 -> conv5_4).\n",
    "        use_input_norm: normaliza la entrada con los valores de ImageNet.\n",
    "        \"\"\"\n",
    "        super(VGGFeatureExtractor, self).__init__()\n",
    "        vgg19 = models.vgg19(pretrained=True).features.to(device).eval()\n",
    "        \n",
    "        self.use_input_norm = use_input_norm\n",
    "        if use_input_norm:\n",
    "            self.register_buffer('mean', torch.Tensor([0.485, 0.456, 0.406]).view(1,3,1,1)) #Media\n",
    "            self.register_buffer('std',  torch.Tensor([0.229, 0.224, 0.225]).view(1,3,1,1))\n",
    "        \n",
    "        # Construir un módulo que incluya todas las capas hasta la máxima layer_id\n",
    "        max_id = max(layer_ids)\n",
    "        self.features = nn.Sequential(*[vgg19[i] for i in range(max_id+1)])\n",
    "        self.layer_ids = layer_ids\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_input_norm:\n",
    "            x = (x - self.mean) / self.std\n",
    "        outputs = []\n",
    "        for idx, layer in enumerate(self.features):\n",
    "            x = layer(x)\n",
    "            if idx in self.layer_ids:\n",
    "                outputs.append(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#En un el ESRGAN tradicional no se considera la perdida de color.\n",
    "#Pero yo percibia que se perdia tras pasar una imagen sobre el modelo ya entrenado.\n",
    "#Así que decidí extender el entrenamiento para que considere la perdida de color\n",
    "\n",
    "#Es necesaria la conversion para extraer la informacion de luminencia(Y) y  crominancia (Cb y Cr)\n",
    "#Al separarlos podemos penalizar errores de color sin afectar la parte de brillo y viceversa\n",
    "def rgb_to_ycbcr_batch(rgb_tensor: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convierte un tensor de forma (B, 3, H, W) en espacio RGB (0..1) \n",
    "    a YCbCr (también normalizado en 0..1).\n",
    "\n",
    "\n",
    "    Utilizamos la conversión estándar:\n",
    "      Y  =  0.299 R + 0.587 G + 0.114 B\n",
    "      Cb = -0.168736 R - 0.331264 G + 0.5    B + 0.5\n",
    "      Cr =  0.5    R - 0.418688 G - 0.081312 B + 0.5\n",
    "    \"\"\"\n",
    "    # forma (B,3,H,W) B imagenes con los 3 colores con una altura H y anchura W\n",
    "    R = rgb_tensor[:, 0:1, :, :]  #Nada mas nos quedamos con el color rojo\n",
    "    G = rgb_tensor[:, 1:2, :, :]  #Nada mas nos quedamos con el color verde\n",
    "    B = rgb_tensor[:, 2:3, :, :]  #Nada mas nos quedamos con el color azul\n",
    "\n",
    "    Y = 0.299 * R + 0.587 * G + 0.114 * B\n",
    "    Cb = -0.168736 * R - 0.331264 * G + 0.5 * B + 0.5\n",
    "    Cr = 0.5 * R - 0.418688 * G - 0.081312 * B + 0.5\n",
    "\n",
    "    return torch.cat([Y, Cb, Cr], dim=1)  # (B,3,H,W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/pateaAbuelitas/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jose/miniconda3/envs/pateaAbuelitas/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#Podemos proceder a definir todas las cosas que vamos a ocupar para el entrenamiento\n",
    "\n",
    "generator = RRDBNet(\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    num_features=64,\n",
    "    growth_channels=32,\n",
    "    num_blocks=23,\n",
    "    scale=4\n",
    ").to(device)\n",
    "\n",
    "discriminator = Discriminator(in_channels=3, base_channels=64).to(device)\n",
    "lr_initial = 5e-5 # 1e-4 las primeras 95 epocas #Se ocupa 5e-5 a partir de la 95 epoca\n",
    "\n",
    "#Optimizadores adam  con los siguientes parametros es lo usual en ESRGAN\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr_initial, betas=(0.9, 0.999)) #Optimizador para el generador\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr_initial, betas=(0.9, 0.999)) #Optimizador para el Discrimiandor\n",
    "pixel_loss = nn.L1Loss().to(device)\n",
    "\n",
    "vgg_extractor = VGGFeatureExtractor(layer_ids=[35], use_input_norm=True).to(device)\n",
    "\n",
    "# Función de pérdida perceptual (L1 sobre características) (L2 solo penaliza pero no elimina caracteristicas, L1 penaliza y hace seleccion de caracteristicas)\n",
    "perceptual_loss = nn.L1Loss().to(device) \n",
    "bce_loss = nn.BCEWithLogitsLoss().to(device) #Probabilidades de real y fake por parte del discriminador\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/130], Step [100/212], Loss_D: 0.0224, Loss_G: 0.3347, Pixel: 0.0778, Percep: 0.1448, Adv: 4.3020, Color: 0.0643, Tiempo iter: 82.9s\n",
      "Epoch [1/130], Step [200/212], Loss_D: 0.2785, Loss_G: 0.2558, Pixel: 0.0573, Percep: 0.1243, Adv: 1.9696, Color: 0.0522, Tiempo iter: 166.8s\n",
      "Epoch [1/130], Pixel: 0.0607, Percep: 0.1336, Color: 0.0540, Tiempo de época: 189.1s\n",
      "Epoch [2/130], Step [100/212], Loss_D: 0.5912, Loss_G: 0.2970, Pixel: 0.0633, Percep: 0.1554, Adv: 1.4454, Color: 0.0541, Tiempo iter: 85.4s\n",
      "Epoch [2/130], Step [200/212], Loss_D: 0.2158, Loss_G: 0.2153, Pixel: 0.0413, Percep: 0.1010, Adv: 3.1273, Color: 0.0406, Tiempo iter: 170.0s\n",
      "Epoch [2/130], Pixel: 0.0519, Percep: 0.1268, Color: 0.0490, Tiempo de época: 193.0s\n",
      "Epoch [3/130], Step [100/212], Loss_D: 0.6841, Loss_G: 0.2155, Pixel: 0.0481, Percep: 0.1105, Adv: 0.9991, Color: 0.0387, Tiempo iter: 86.3s\n",
      "Epoch [3/130], Step [200/212], Loss_D: 1.1114, Loss_G: 0.2160, Pixel: 0.0427, Percep: 0.1238, Adv: 0.2649, Color: 0.0362, Tiempo iter: 171.2s\n",
      "Epoch [3/130], Pixel: 0.0472, Percep: 0.1240, Color: 0.0382, Tiempo de época: 193.4s\n",
      "Epoch [4/130], Step [100/212], Loss_D: 0.1196, Loss_G: 0.2608, Pixel: 0.0545, Percep: 0.1205, Adv: 3.3462, Color: 0.0465, Tiempo iter: 86.1s\n",
      "Epoch [4/130], Step [200/212], Loss_D: 0.1918, Loss_G: 0.2690, Pixel: 0.0464, Percep: 0.1522, Adv: 1.5956, Color: 0.0381, Tiempo iter: 171.2s\n",
      "Epoch [4/130], Pixel: 0.0603, Percep: 0.1215, Color: 0.0361, Tiempo de época: 194.5s\n",
      "Epoch [5/130], Step [100/212], Loss_D: 0.0782, Loss_G: 0.2422, Pixel: 0.0487, Percep: 0.1162, Adv: 2.9004, Color: 0.0375, Tiempo iter: 86.7s\n",
      "Epoch [5/130], Step [200/212], Loss_D: 1.7842, Loss_G: 0.1917, Pixel: 0.0373, Percep: 0.0847, Adv: 3.3516, Color: 0.0312, Tiempo iter: 172.4s\n",
      "Epoch [5/130], Pixel: 0.0527, Percep: 0.1246, Color: 0.0356, Tiempo de época: 194.6s\n",
      "Epoch [6/130], Step [100/212], Loss_D: 0.2866, Loss_G: 0.2805, Pixel: 0.0600, Percep: 0.1524, Adv: 0.6683, Color: 0.0444, Tiempo iter: 86.2s\n",
      "Epoch [6/130], Step [200/212], Loss_D: 0.1821, Loss_G: 0.2258, Pixel: 0.0396, Percep: 0.1089, Adv: 3.5139, Color: 0.0289, Tiempo iter: 171.3s\n",
      "Epoch [6/130], Pixel: 0.0472, Percep: 0.1223, Color: 0.0348, Tiempo de época: 194.0s\n",
      "Epoch [7/130], Step [100/212], Loss_D: 0.1000, Loss_G: 0.2959, Pixel: 0.0547, Percep: 0.1426, Adv: 4.1972, Color: 0.0349, Tiempo iter: 86.6s\n",
      "Epoch [7/130], Step [200/212], Loss_D: 0.0543, Loss_G: 0.2061, Pixel: 0.0291, Percep: 0.1098, Adv: 3.0210, Color: 0.0213, Tiempo iter: 171.8s\n",
      "Epoch [7/130], Pixel: 0.0466, Percep: 0.1136, Color: 0.0275, Tiempo de época: 194.1s\n",
      "Epoch [8/130], Step [100/212], Loss_D: 0.4632, Loss_G: 0.2087, Pixel: 0.0383, Percep: 0.1141, Adv: 1.3881, Color: 0.0271, Tiempo iter: 86.2s\n",
      "Epoch [8/130], Step [200/212], Loss_D: 0.0955, Loss_G: 0.2001, Pixel: 0.0395, Percep: 0.1006, Adv: 1.9641, Color: 0.0278, Tiempo iter: 172.0s\n",
      "Epoch [8/130], Pixel: 0.0433, Percep: 0.1184, Color: 0.0296, Tiempo de época: 194.8s\n",
      "Epoch [9/130], Step [100/212], Loss_D: 0.1393, Loss_G: 0.2940, Pixel: 0.0526, Percep: 0.1627, Adv: 1.9060, Color: 0.0387, Tiempo iter: 86.6s\n",
      "Epoch [9/130], Step [200/212], Loss_D: 0.0819, Loss_G: 0.2533, Pixel: 0.0544, Percep: 0.1198, Adv: 2.7502, Color: 0.0283, Tiempo iter: 171.7s\n",
      "Epoch [9/130], Pixel: 0.0416, Percep: 0.1131, Color: 0.0253, Tiempo de época: 194.0s\n",
      "Epoch [10/130], Step [100/212], Loss_D: 0.1215, Loss_G: 0.2017, Pixel: 0.0374, Percep: 0.0997, Adv: 2.5442, Color: 0.0237, Tiempo iter: 86.7s\n",
      "Epoch [10/130], Step [200/212], Loss_D: 0.0266, Loss_G: 0.2159, Pixel: 0.0402, Percep: 0.0986, Adv: 3.6737, Color: 0.0249, Tiempo iter: 171.9s\n",
      "Epoch [10/130], Pixel: 0.0470, Percep: 0.1131, Color: 0.0278, Tiempo de época: 194.1s\n",
      "Epoch [11/130], Step [100/212], Loss_D: 1.0060, Loss_G: 0.2267, Pixel: 0.0567, Percep: 0.0997, Adv: 2.1358, Color: 0.0343, Tiempo iter: 85.6s\n",
      "Epoch [11/130], Step [200/212], Loss_D: 0.5635, Loss_G: 0.2115, Pixel: 0.0492, Percep: 0.0866, Adv: 3.3281, Color: 0.0284, Tiempo iter: 170.9s\n",
      "Epoch [11/130], Pixel: 0.0493, Percep: 0.1162, Color: 0.0305, Tiempo de época: 193.3s\n",
      "Epoch [12/130], Step [100/212], Loss_D: 0.1099, Loss_G: 0.2090, Pixel: 0.0348, Percep: 0.0967, Adv: 4.0357, Color: 0.0220, Tiempo iter: 85.9s\n",
      "Epoch [12/130], Step [200/212], Loss_D: 0.3028, Loss_G: 0.2072, Pixel: 0.0352, Percep: 0.1168, Adv: 1.3799, Color: 0.0243, Tiempo iter: 171.3s\n",
      "Epoch [12/130], Pixel: 0.0416, Percep: 0.1099, Color: 0.0256, Tiempo de época: 193.7s\n",
      "Epoch [13/130], Step [100/212], Loss_D: 0.1988, Loss_G: 0.1595, Pixel: 0.0219, Percep: 0.0891, Adv: 1.9315, Color: 0.0158, Tiempo iter: 86.3s\n",
      "Epoch [13/130], Step [200/212], Loss_D: 0.0397, Loss_G: 0.2245, Pixel: 0.0377, Percep: 0.1121, Adv: 3.3073, Color: 0.0207, Tiempo iter: 171.2s\n",
      "Epoch [13/130], Pixel: 0.0486, Percep: 0.1228, Color: 0.0304, Tiempo de época: 193.4s\n",
      "Epoch [14/130], Step [100/212], Loss_D: 1.0625, Loss_G: 0.2464, Pixel: 0.0569, Percep: 0.1312, Adv: 0.2929, Color: 0.0319, Tiempo iter: 86.0s\n",
      "Epoch [14/130], Step [200/212], Loss_D: 0.0436, Loss_G: 0.2495, Pixel: 0.0474, Percep: 0.1209, Adv: 3.2664, Color: 0.0317, Tiempo iter: 171.0s\n",
      "Epoch [14/130], Pixel: 0.0404, Percep: 0.1109, Color: 0.0236, Tiempo de época: 193.7s\n",
      "Epoch [15/130], Step [100/212], Loss_D: 0.6618, Loss_G: 0.1789, Pixel: 0.0391, Percep: 0.0808, Adv: 2.2765, Color: 0.0230, Tiempo iter: 86.9s\n",
      "Epoch [15/130], Step [200/212], Loss_D: 0.0870, Loss_G: 0.2173, Pixel: 0.0425, Percep: 0.1018, Adv: 3.0940, Color: 0.0215, Tiempo iter: 172.5s\n",
      "Epoch [15/130], Pixel: 0.0428, Percep: 0.1154, Color: 0.0259, Tiempo de época: 194.7s\n",
      "Epoch [16/130], Step [100/212], Loss_D: 0.3305, Loss_G: 0.1623, Pixel: 0.0384, Percep: 0.0774, Adv: 1.1250, Color: 0.0222, Tiempo iter: 86.0s\n",
      "Epoch [16/130], Step [200/212], Loss_D: 0.3203, Loss_G: 0.2008, Pixel: 0.0331, Percep: 0.1146, Adv: 1.3146, Color: 0.0223, Tiempo iter: 171.0s\n",
      "Epoch [16/130], Pixel: 0.0421, Percep: 0.1102, Color: 0.0238, Tiempo de época: 193.3s\n",
      "Epoch [17/130], Step [100/212], Loss_D: 0.3989, Loss_G: 0.2181, Pixel: 0.0329, Percep: 0.1145, Adv: 3.0875, Color: 0.0207, Tiempo iter: 86.3s\n",
      "Epoch [17/130], Step [200/212], Loss_D: 0.0922, Loss_G: 0.2404, Pixel: 0.0553, Percep: 0.1068, Adv: 2.8644, Color: 0.0304, Tiempo iter: 171.7s\n",
      "Epoch [17/130], Pixel: 0.0465, Percep: 0.1176, Color: 0.0262, Tiempo de época: 196.0s\n",
      "Epoch [18/130], Step [100/212], Loss_D: 0.2787, Loss_G: 0.2522, Pixel: 0.0668, Percep: 0.1115, Adv: 1.7555, Color: 0.0326, Tiempo iter: 87.1s\n",
      "Epoch [18/130], Step [200/212], Loss_D: 0.1095, Loss_G: 0.1856, Pixel: 0.0325, Percep: 0.0965, Adv: 2.0538, Color: 0.0200, Tiempo iter: 172.6s\n",
      "Epoch [18/130], Pixel: 0.0439, Percep: 0.1100, Color: 0.0248, Tiempo de época: 196.0s\n",
      "Epoch [19/130], Step [100/212], Loss_D: 0.3874, Loss_G: 0.1827, Pixel: 0.0232, Percep: 0.1049, Adv: 2.1622, Color: 0.0196, Tiempo iter: 87.4s\n",
      "Epoch [19/130], Step [200/212], Loss_D: 0.1654, Loss_G: 0.2249, Pixel: 0.0477, Percep: 0.1060, Adv: 2.5613, Color: 0.0264, Tiempo iter: 173.2s\n",
      "Epoch [19/130], Pixel: 0.0453, Percep: 0.1158, Color: 0.0287, Tiempo de época: 195.8s\n",
      "Epoch [20/130], Step [100/212], Loss_D: 0.1494, Loss_G: 0.2133, Pixel: 0.0338, Percep: 0.1154, Adv: 2.3770, Color: 0.0210, Tiempo iter: 86.7s\n",
      "Epoch [20/130], Step [200/212], Loss_D: 0.1155, Loss_G: 0.2109, Pixel: 0.0357, Percep: 0.1051, Adv: 3.0846, Color: 0.0191, Tiempo iter: 172.0s\n",
      "Epoch [20/130], Pixel: 0.0422, Percep: 0.1103, Color: 0.0230, Tiempo de época: 194.5s\n",
      "Epoch [21/130], Step [100/212], Loss_D: 0.1740, Loss_G: 0.1546, Pixel: 0.0292, Percep: 0.0787, Adv: 1.6056, Color: 0.0178, Tiempo iter: 86.3s\n",
      "Epoch [21/130], Step [200/212], Loss_D: 0.1225, Loss_G: 0.2355, Pixel: 0.0371, Percep: 0.1302, Adv: 2.3109, Color: 0.0238, Tiempo iter: 171.3s\n",
      "Epoch [21/130], Pixel: 0.0475, Percep: 0.1160, Color: 0.0284, Tiempo de época: 193.7s\n",
      "Epoch [22/130], Step [100/212], Loss_D: 0.6357, Loss_G: 0.2476, Pixel: 0.0628, Percep: 0.1214, Adv: 0.7054, Color: 0.0293, Tiempo iter: 86.4s\n",
      "Epoch [22/130], Step [200/212], Loss_D: 0.1034, Loss_G: 0.2432, Pixel: 0.0485, Percep: 0.1163, Adv: 3.0176, Color: 0.0355, Tiempo iter: 171.5s\n",
      "Epoch [22/130], Pixel: 0.0407, Percep: 0.1079, Color: 0.0262, Tiempo de época: 194.1s\n",
      "Epoch [23/130], Step [100/212], Loss_D: 0.0667, Loss_G: 0.2179, Pixel: 0.0396, Percep: 0.1114, Adv: 2.4250, Color: 0.0234, Tiempo iter: 86.2s\n",
      "Epoch [23/130], Step [200/212], Loss_D: 0.7550, Loss_G: 0.1880, Pixel: 0.0376, Percep: 0.0714, Adv: 4.5447, Color: 0.0182, Tiempo iter: 171.1s\n",
      "Epoch [23/130], Pixel: 0.0467, Percep: 0.1100, Color: 0.0299, Tiempo de época: 193.5s\n",
      "Epoch [24/130], Step [100/212], Loss_D: 0.9601, Loss_G: 0.2520, Pixel: 0.0601, Percep: 0.1322, Adv: 0.2542, Color: 0.0310, Tiempo iter: 86.2s\n",
      "Epoch [24/130], Step [200/212], Loss_D: 0.2327, Loss_G: 0.2217, Pixel: 0.0489, Percep: 0.1024, Adv: 2.4939, Color: 0.0269, Tiempo iter: 171.4s\n",
      "Epoch [24/130], Pixel: 0.0496, Percep: 0.1131, Color: 0.0242, Tiempo de época: 193.9s\n",
      "Epoch [25/130], Step [100/212], Loss_D: 1.4771, Loss_G: 0.2317, Pixel: 0.0365, Percep: 0.1099, Adv: 4.4632, Color: 0.0239, Tiempo iter: 86.2s\n",
      "Epoch [25/130], Step [200/212], Loss_D: 0.3035, Loss_G: 0.1943, Pixel: 0.0411, Percep: 0.0967, Adv: 1.6213, Color: 0.0213, Tiempo iter: 171.2s\n",
      "Epoch [25/130], Pixel: 0.0458, Percep: 0.1092, Color: 0.0225, Tiempo de época: 193.6s\n",
      "Epoch [26/130], Step [100/212], Loss_D: 0.0793, Loss_G: 0.2011, Pixel: 0.0364, Percep: 0.0992, Adv: 2.7172, Color: 0.0182, Tiempo iter: 86.3s\n",
      "Epoch [26/130], Step [200/212], Loss_D: 0.4685, Loss_G: 0.1869, Pixel: 0.0335, Percep: 0.0890, Adv: 2.9452, Color: 0.0206, Tiempo iter: 171.4s\n",
      "Epoch [26/130], Pixel: 0.0477, Percep: 0.1154, Color: 0.0249, Tiempo de época: 193.8s\n",
      "Epoch [27/130], Step [100/212], Loss_D: 0.0295, Loss_G: 0.2847, Pixel: 0.0505, Percep: 0.1432, Adv: 3.6670, Color: 0.0209, Tiempo iter: 86.7s\n",
      "Epoch [27/130], Step [200/212], Loss_D: 1.2030, Loss_G: 0.2296, Pixel: 0.0497, Percep: 0.0966, Adv: 3.8482, Color: 0.0315, Tiempo iter: 172.1s\n",
      "Epoch [27/130], Pixel: 0.0389, Percep: 0.1035, Color: 0.0213, Tiempo de época: 194.0s\n",
      "Epoch [28/130], Step [100/212], Loss_D: 0.1649, Loss_G: 0.2608, Pixel: 0.0551, Percep: 0.1318, Adv: 1.9460, Color: 0.0264, Tiempo iter: 85.4s\n",
      "Epoch [28/130], Step [200/212], Loss_D: 0.4461, Loss_G: 0.2489, Pixel: 0.0576, Percep: 0.1273, Adv: 0.9185, Color: 0.0322, Tiempo iter: 170.6s\n",
      "Epoch [28/130], Pixel: 0.0468, Percep: 0.1087, Color: 0.0243, Tiempo de época: 192.8s\n",
      "Epoch [29/130], Step [100/212], Loss_D: 0.5366, Loss_G: 0.2734, Pixel: 0.0551, Percep: 0.1462, Adv: 1.4717, Color: 0.0298, Tiempo iter: 86.1s\n",
      "Epoch [29/130], Step [200/212], Loss_D: 1.6510, Loss_G: 0.1535, Pixel: 0.0200, Percep: 0.0704, Adv: 3.8691, Color: 0.0132, Tiempo iter: 170.8s\n",
      "Epoch [29/130], Pixel: 0.0376, Percep: 0.1029, Color: 0.0198, Tiempo de época: 192.8s\n",
      "Epoch [30/130], Step [100/212], Loss_D: 0.2310, Loss_G: 0.2532, Pixel: 0.0443, Percep: 0.1391, Adv: 1.9272, Color: 0.0290, Tiempo iter: 85.8s\n",
      "Epoch [30/130], Step [200/212], Loss_D: 0.0498, Loss_G: 0.2139, Pixel: 0.0426, Percep: 0.0906, Adv: 4.0789, Color: 0.0245, Tiempo iter: 171.0s\n",
      "Epoch [30/130], Pixel: 0.0404, Percep: 0.1031, Color: 0.0191, Tiempo de época: 193.0s\n",
      "Epoch [31/130], Step [100/212], Loss_D: 0.1998, Loss_G: 0.3062, Pixel: 0.0415, Percep: 0.1710, Adv: 3.8242, Color: 0.0288, Tiempo iter: 86.7s\n",
      "Epoch [31/130], Step [200/212], Loss_D: 0.8116, Loss_G: 0.2226, Pixel: 0.0617, Percep: 0.1012, Adv: 0.7972, Color: 0.0279, Tiempo iter: 171.8s\n",
      "Epoch [31/130], Pixel: 0.0436, Percep: 0.1074, Color: 0.0234, Tiempo de época: 194.0s\n",
      "Epoch [32/130], Step [100/212], Loss_D: 0.2321, Loss_G: 0.1764, Pixel: 0.0323, Percep: 0.0912, Adv: 1.8111, Color: 0.0189, Tiempo iter: 86.1s\n",
      "Epoch [32/130], Step [200/212], Loss_D: 0.5471, Loss_G: 0.2075, Pixel: 0.0286, Percep: 0.1164, Adv: 2.4515, Color: 0.0178, Tiempo iter: 170.9s\n",
      "Epoch [32/130], Pixel: 0.0423, Percep: 0.1095, Color: 0.0235, Tiempo de época: 193.8s\n",
      "Epoch [33/130], Step [100/212], Loss_D: 0.3196, Loss_G: 0.2226, Pixel: 0.0358, Percep: 0.1212, Adv: 2.3088, Color: 0.0235, Tiempo iter: 86.1s\n",
      "Epoch [33/130], Step [200/212], Loss_D: 0.2338, Loss_G: 0.2050, Pixel: 0.0373, Percep: 0.1017, Adv: 2.6659, Color: 0.0186, Tiempo iter: 172.6s\n",
      "Epoch [33/130], Pixel: 0.0424, Percep: 0.1050, Color: 0.0237, Tiempo de época: 195.0s\n",
      "Epoch [34/130], Step [100/212], Loss_D: 0.1620, Loss_G: 0.2030, Pixel: 0.0399, Percep: 0.1036, Adv: 1.8427, Color: 0.0218, Tiempo iter: 86.8s\n",
      "Epoch [34/130], Step [200/212], Loss_D: 0.6311, Loss_G: 0.2448, Pixel: 0.0621, Percep: 0.1203, Adv: 0.6729, Color: 0.0266, Tiempo iter: 172.8s\n",
      "Epoch [34/130], Pixel: 0.0390, Percep: 0.1075, Color: 0.0196, Tiempo de época: 195.7s\n",
      "Epoch [35/130], Step [100/212], Loss_D: 0.3122, Loss_G: 0.2093, Pixel: 0.0423, Percep: 0.1103, Adv: 1.3049, Color: 0.0202, Tiempo iter: 86.7s\n",
      "Epoch [35/130], Step [200/212], Loss_D: 0.6478, Loss_G: 0.2398, Pixel: 0.0707, Percep: 0.1050, Adv: 0.7111, Color: 0.0327, Tiempo iter: 172.0s\n",
      "Epoch [35/130], Pixel: 0.0408, Percep: 0.1066, Color: 0.0211, Tiempo de época: 194.5s\n",
      "Epoch [36/130], Step [100/212], Loss_D: 0.3952, Loss_G: 0.2079, Pixel: 0.0429, Percep: 0.0972, Adv: 2.6532, Color: 0.0241, Tiempo iter: 86.5s\n",
      "Epoch [36/130], Step [200/212], Loss_D: 0.1957, Loss_G: 0.2162, Pixel: 0.0384, Percep: 0.1067, Adv: 3.0057, Color: 0.0241, Tiempo iter: 171.7s\n",
      "Epoch [36/130], Pixel: 0.0424, Percep: 0.1127, Color: 0.0213, Tiempo de época: 194.3s\n",
      "Epoch [37/130], Step [100/212], Loss_D: 0.2797, Loss_G: 0.1994, Pixel: 0.0389, Percep: 0.0857, Adv: 3.7808, Color: 0.0183, Tiempo iter: 86.4s\n",
      "Epoch [37/130], Step [200/212], Loss_D: 0.4024, Loss_G: 0.2261, Pixel: 0.0486, Percep: 0.0967, Adv: 3.6677, Color: 0.0235, Tiempo iter: 171.4s\n",
      "Epoch [37/130], Pixel: 0.0462, Percep: 0.1088, Color: 0.0259, Tiempo de época: 194.0s\n",
      "Epoch [38/130], Step [100/212], Loss_D: 0.0975, Loss_G: 0.2169, Pixel: 0.0383, Percep: 0.1110, Adv: 2.5870, Color: 0.0174, Tiempo iter: 86.4s\n",
      "Epoch [38/130], Step [200/212], Loss_D: 0.3791, Loss_G: 0.2173, Pixel: 0.0331, Percep: 0.1180, Adv: 2.5532, Color: 0.0202, Tiempo iter: 171.4s\n",
      "Epoch [38/130], Pixel: 0.0396, Percep: 0.1009, Color: 0.0209, Tiempo de época: 193.9s\n",
      "Epoch [39/130], Step [100/212], Loss_D: 0.4339, Loss_G: 0.2462, Pixel: 0.0505, Percep: 0.1321, Adv: 1.1479, Color: 0.0220, Tiempo iter: 86.2s\n",
      "Epoch [39/130], Step [200/212], Loss_D: 0.5192, Loss_G: 0.2008, Pixel: 0.0456, Percep: 0.1012, Adv: 1.0426, Color: 0.0247, Tiempo iter: 171.1s\n",
      "Epoch [39/130], Pixel: 0.0390, Percep: 0.1026, Color: 0.0219, Tiempo de época: 193.6s\n",
      "Epoch [40/130], Step [100/212], Loss_D: 0.6013, Loss_G: 0.2570, Pixel: 0.0436, Percep: 0.1411, Adv: 2.1686, Color: 0.0228, Tiempo iter: 86.3s\n",
      "Epoch [40/130], Step [200/212], Loss_D: 0.1851, Loss_G: 0.2070, Pixel: 0.0358, Percep: 0.1008, Adv: 3.1905, Color: 0.0240, Tiempo iter: 171.2s\n",
      "Epoch [40/130], Pixel: 0.0417, Percep: 0.1080, Color: 0.0221, Tiempo de época: 193.6s\n",
      "Epoch [41/130], Step [100/212], Loss_D: 0.6808, Loss_G: 0.2007, Pixel: 0.0482, Percep: 0.1022, Adv: 0.5343, Color: 0.0259, Tiempo iter: 86.1s\n",
      "Epoch [41/130], Step [200/212], Loss_D: 0.7619, Loss_G: 0.2585, Pixel: 0.0639, Percep: 0.1285, Adv: 0.7685, Color: 0.0357, Tiempo iter: 171.1s\n",
      "Epoch [41/130], Pixel: 0.0443, Percep: 0.1033, Color: 0.0242, Tiempo de época: 193.6s\n",
      "Epoch [42/130], Step [100/212], Loss_D: 0.3789, Loss_G: 0.2279, Pixel: 0.0497, Percep: 0.1052, Adv: 2.6628, Color: 0.0256, Tiempo iter: 86.1s\n",
      "Epoch [42/130], Step [200/212], Loss_D: 0.3356, Loss_G: 0.2467, Pixel: 0.0594, Percep: 0.1214, Adv: 1.1348, Color: 0.0302, Tiempo iter: 171.0s\n",
      "Epoch [42/130], Pixel: 0.0393, Percep: 0.1018, Color: 0.0215, Tiempo de época: 193.5s\n",
      "Epoch [43/130], Step [100/212], Loss_D: 0.3638, Loss_G: 0.2421, Pixel: 0.0522, Percep: 0.1268, Adv: 1.1121, Color: 0.0252, Tiempo iter: 86.1s\n",
      "Epoch [43/130], Step [200/212], Loss_D: 0.5952, Loss_G: 0.2260, Pixel: 0.0387, Percep: 0.1050, Adv: 4.1467, Color: 0.0221, Tiempo iter: 170.9s\n",
      "Epoch [43/130], Pixel: 0.0370, Percep: 0.1010, Color: 0.0190, Tiempo de época: 193.2s\n",
      "Epoch [44/130], Step [100/212], Loss_D: 0.2671, Loss_G: 0.2101, Pixel: 0.0412, Percep: 0.1129, Adv: 1.2529, Color: 0.0190, Tiempo iter: 86.3s\n",
      "Epoch [44/130], Step [200/212], Loss_D: 0.4832, Loss_G: 0.1678, Pixel: 0.0366, Percep: 0.0879, Adv: 0.7045, Color: 0.0203, Tiempo iter: 171.1s\n",
      "Epoch [44/130], Pixel: 0.0442, Percep: 0.1027, Color: 0.0242, Tiempo de época: 193.6s\n",
      "Epoch [45/130], Step [100/212], Loss_D: 0.1745, Loss_G: 0.2227, Pixel: 0.0377, Percep: 0.1210, Adv: 2.0572, Color: 0.0178, Tiempo iter: 86.0s\n",
      "Epoch [45/130], Step [200/212], Loss_D: 0.2111, Loss_G: 0.1977, Pixel: 0.0404, Percep: 0.0953, Adv: 2.2255, Color: 0.0243, Tiempo iter: 170.9s\n",
      "Epoch [45/130], Pixel: 0.0392, Percep: 0.1034, Color: 0.0210, Tiempo de época: 193.2s\n",
      "Epoch [46/130], Step [100/212], Loss_D: 0.0790, Loss_G: 0.1634, Pixel: 0.0314, Percep: 0.0743, Adv: 2.6875, Color: 0.0177, Tiempo iter: 86.3s\n",
      "Epoch [46/130], Step [200/212], Loss_D: 0.3725, Loss_G: 0.2620, Pixel: 0.0372, Percep: 0.1366, Adv: 4.1875, Color: 0.0200, Tiempo iter: 171.4s\n",
      "Epoch [46/130], Pixel: 0.0420, Percep: 0.1045, Color: 0.0212, Tiempo de época: 194.0s\n",
      "Epoch [47/130], Step [100/212], Loss_D: 0.3506, Loss_G: 0.1402, Pixel: 0.0275, Percep: 0.0659, Adv: 1.9592, Color: 0.0159, Tiempo iter: 86.5s\n",
      "Epoch [47/130], Step [200/212], Loss_D: 0.4831, Loss_G: 0.2546, Pixel: 0.0484, Percep: 0.1396, Adv: 1.4022, Color: 0.0212, Tiempo iter: 171.5s\n",
      "Epoch [47/130], Pixel: 0.0428, Percep: 0.1093, Color: 0.0216, Tiempo de época: 194.2s\n",
      "Epoch [48/130], Step [100/212], Loss_D: 0.4951, Loss_G: 0.2160, Pixel: 0.0455, Percep: 0.1121, Adv: 1.2700, Color: 0.0237, Tiempo iter: 86.4s\n",
      "Epoch [48/130], Step [200/212], Loss_D: 0.2272, Loss_G: 0.2371, Pixel: 0.0422, Percep: 0.1223, Adv: 2.6645, Color: 0.0204, Tiempo iter: 171.4s\n",
      "Epoch [48/130], Pixel: 0.0403, Percep: 0.1060, Color: 0.0197, Tiempo de época: 193.9s\n",
      "Epoch [49/130], Step [100/212], Loss_D: 0.2562, Loss_G: 0.2252, Pixel: 0.0472, Percep: 0.1085, Adv: 2.3679, Color: 0.0199, Tiempo iter: 86.3s\n",
      "Epoch [49/130], Step [200/212], Loss_D: 0.1594, Loss_G: 0.2632, Pixel: 0.0598, Percep: 0.1156, Adv: 3.4316, Color: 0.0228, Tiempo iter: 171.4s\n",
      "Epoch [49/130], Pixel: 0.0372, Percep: 0.1039, Color: 0.0212, Tiempo de época: 194.9s\n",
      "Epoch [50/130], Step [100/212], Loss_D: 0.1084, Loss_G: 0.2226, Pixel: 0.0395, Percep: 0.1170, Adv: 2.2485, Color: 0.0235, Tiempo iter: 87.1s\n",
      "Epoch [50/130], Step [200/212], Loss_D: 0.4035, Loss_G: 0.2486, Pixel: 0.0526, Percep: 0.1281, Adv: 1.5670, Color: 0.0218, Tiempo iter: 173.5s\n",
      "Epoch [50/130], Pixel: 0.0391, Percep: 0.1043, Color: 0.0218, Tiempo de época: 197.6s\n",
      "Epoch [51/130], Step [100/212], Loss_D: 0.6071, Loss_G: 0.2138, Pixel: 0.0303, Percep: 0.1142, Adv: 3.0994, Color: 0.0172, Tiempo iter: 87.7s\n",
      "Epoch [51/130], Step [200/212], Loss_D: 0.2504, Loss_G: 0.2328, Pixel: 0.0673, Percep: 0.0919, Adv: 2.0881, Color: 0.0289, Tiempo iter: 173.1s\n",
      "Epoch [51/130], Pixel: 0.0432, Percep: 0.1085, Color: 0.0218, Tiempo de época: 195.4s\n",
      "Epoch [52/130], Step [100/212], Loss_D: 0.5052, Loss_G: 0.2278, Pixel: 0.0321, Percep: 0.1229, Adv: 3.1778, Color: 0.0169, Tiempo iter: 86.3s\n",
      "Epoch [52/130], Step [200/212], Loss_D: 0.1385, Loss_G: 0.1865, Pixel: 0.0432, Percep: 0.0827, Adv: 2.2072, Color: 0.0201, Tiempo iter: 171.5s\n",
      "Epoch [52/130], Pixel: 0.0393, Percep: 0.1058, Color: 0.0202, Tiempo de época: 193.7s\n",
      "Epoch [53/130], Step [100/212], Loss_D: 0.3495, Loss_G: 0.2071, Pixel: 0.0377, Percep: 0.1166, Adv: 1.0168, Color: 0.0214, Tiempo iter: 179.9s\n",
      "Epoch [53/130], Step [200/212], Loss_D: 0.1257, Loss_G: 0.2276, Pixel: 0.0458, Percep: 0.1086, Adv: 2.8002, Color: 0.0281, Tiempo iter: 270.0s\n",
      "Epoch [53/130], Pixel: 0.0423, Percep: 0.1047, Color: 0.0234, Tiempo de época: 292.5s\n",
      "Epoch [54/130], Step [100/212], Loss_D: 0.9526, Loss_G: 0.1765, Pixel: 0.0320, Percep: 0.0798, Adv: 3.2466, Color: 0.0163, Tiempo iter: 87.0s\n",
      "Epoch [54/130], Step [200/212], Loss_D: 0.4854, Loss_G: 0.1904, Pixel: 0.0329, Percep: 0.1081, Adv: 1.1046, Color: 0.0178, Tiempo iter: 172.8s\n",
      "Epoch [54/130], Pixel: 0.0393, Percep: 0.0987, Color: 0.0197, Tiempo de época: 195.6s\n",
      "Epoch [55/130], Step [100/212], Loss_D: 0.5969, Loss_G: 0.1555, Pixel: 0.0460, Percep: 0.0654, Adv: 0.7626, Color: 0.0227, Tiempo iter: 86.9s\n",
      "Epoch [55/130], Step [200/212], Loss_D: 0.1296, Loss_G: 0.1834, Pixel: 0.0393, Percep: 0.0892, Adv: 1.6992, Color: 0.0167, Tiempo iter: 172.3s\n",
      "Epoch [55/130], Pixel: 0.0405, Percep: 0.1073, Color: 0.0217, Tiempo de época: 195.0s\n",
      "Epoch [56/130], Step [100/212], Loss_D: 0.1020, Loss_G: 0.2124, Pixel: 0.0498, Percep: 0.0900, Adv: 2.9309, Color: 0.0245, Tiempo iter: 136.2s\n",
      "Epoch [56/130], Step [200/212], Loss_D: 0.2385, Loss_G: 0.2374, Pixel: 0.0338, Percep: 0.1219, Adv: 4.0046, Color: 0.0186, Tiempo iter: 288.2s\n",
      "Epoch [56/130], Pixel: 0.0394, Percep: 0.0997, Color: 0.0194, Tiempo de época: 311.4s\n",
      "Epoch [57/130], Step [100/212], Loss_D: 0.3491, Loss_G: 0.2533, Pixel: 0.0624, Percep: 0.1143, Adv: 2.2010, Color: 0.0242, Tiempo iter: 87.6s\n",
      "Epoch [57/130], Step [200/212], Loss_D: 0.0750, Loss_G: 0.2500, Pixel: 0.0406, Percep: 0.1296, Adv: 3.3185, Color: 0.0212, Tiempo iter: 173.8s\n",
      "Epoch [57/130], Pixel: 0.0397, Percep: 0.1062, Color: 0.0193, Tiempo de época: 196.6s\n",
      "Epoch [58/130], Step [100/212], Loss_D: 0.3395, Loss_G: 0.2065, Pixel: 0.0372, Percep: 0.1160, Adv: 1.1037, Color: 0.0185, Tiempo iter: 87.2s\n",
      "Epoch [58/130], Step [200/212], Loss_D: 0.1346, Loss_G: 0.1948, Pixel: 0.0506, Percep: 0.0816, Adv: 2.0393, Color: 0.0270, Tiempo iter: 173.1s\n",
      "Epoch [58/130], Pixel: 0.0420, Percep: 0.0991, Color: 0.0216, Tiempo de época: 196.5s\n",
      "Epoch [59/130], Step [100/212], Loss_D: 0.1993, Loss_G: 0.2156, Pixel: 0.0335, Percep: 0.1186, Adv: 2.2660, Color: 0.0185, Tiempo iter: 87.0s\n",
      "Epoch [59/130], Step [200/212], Loss_D: 0.5971, Loss_G: 0.2349, Pixel: 0.0460, Percep: 0.1309, Adv: 0.8265, Color: 0.0226, Tiempo iter: 244.5s\n",
      "Epoch [59/130], Pixel: 0.0394, Percep: 0.1000, Color: 0.0204, Tiempo de época: 315.8s\n",
      "Epoch [60/130], Step [100/212], Loss_D: 0.3974, Loss_G: 0.2155, Pixel: 0.0287, Percep: 0.1150, Adv: 3.4037, Color: 0.0215, Tiempo iter: 86.7s\n",
      "Epoch [60/130], Step [200/212], Loss_D: 0.1501, Loss_G: 0.2442, Pixel: 0.0406, Percep: 0.1314, Adv: 2.5068, Color: 0.0211, Tiempo iter: 172.5s\n",
      "Epoch [60/130], Pixel: 0.0382, Percep: 0.0962, Color: 0.0194, Tiempo de época: 195.1s\n",
      "Epoch [61/130], Step [100/212], Loss_D: 0.4229, Loss_G: 0.1945, Pixel: 0.0408, Percep: 0.0924, Adv: 2.2137, Color: 0.0214, Tiempo iter: 87.2s\n",
      "Epoch [61/130], Step [200/212], Loss_D: 1.0138, Loss_G: 0.2677, Pixel: 0.0450, Percep: 0.1598, Adv: 0.7898, Color: 0.0246, Tiempo iter: 227.7s\n",
      "Epoch [61/130], Pixel: 0.0421, Percep: 0.1013, Color: 0.0206, Tiempo de época: 302.9s\n",
      "Epoch [62/130], Step [100/212], Loss_D: 0.5065, Loss_G: 0.1821, Pixel: 0.0346, Percep: 0.0899, Adv: 2.1963, Color: 0.0209, Tiempo iter: 160.3s\n",
      "Epoch [62/130], Step [200/212], Loss_D: 0.2973, Loss_G: 0.1794, Pixel: 0.0337, Percep: 0.0934, Adv: 1.6357, Color: 0.0192, Tiempo iter: 247.5s\n",
      "Epoch [62/130], Pixel: 0.0420, Percep: 0.1053, Color: 0.0227, Tiempo de época: 270.2s\n",
      "Epoch [63/130], Step [100/212], Loss_D: 0.1622, Loss_G: 0.1783, Pixel: 0.0322, Percep: 0.0870, Adv: 2.5341, Color: 0.0159, Tiempo iter: 87.2s\n",
      "Epoch [63/130], Step [200/212], Loss_D: 0.1458, Loss_G: 0.2244, Pixel: 0.0403, Percep: 0.1152, Adv: 2.5216, Color: 0.0247, Tiempo iter: 172.6s\n",
      "Epoch [63/130], Pixel: 0.0416, Percep: 0.1059, Color: 0.0212, Tiempo de época: 194.9s\n",
      "Epoch [64/130], Step [100/212], Loss_D: 0.1296, Loss_G: 0.2220, Pixel: 0.0260, Percep: 0.1232, Adv: 3.4704, Color: 0.0161, Tiempo iter: 172.4s\n",
      "Epoch [64/130], Step [200/212], Loss_D: 0.5743, Loss_G: 0.1388, Pixel: 0.0297, Percep: 0.0641, Adv: 1.6904, Color: 0.0196, Tiempo iter: 454.3s\n",
      "Epoch [64/130], Pixel: 0.0370, Percep: 0.1000, Color: 0.0170, Tiempo de época: 536.1s\n",
      "Epoch [65/130], Step [100/212], Loss_D: 0.2743, Loss_G: 0.2036, Pixel: 0.0496, Percep: 0.0854, Adv: 2.6319, Color: 0.0206, Tiempo iter: 180.9s\n",
      "Epoch [65/130], Step [200/212], Loss_D: 0.1192, Loss_G: 0.2696, Pixel: 0.0465, Percep: 0.1498, Adv: 1.9823, Color: 0.0190, Tiempo iter: 267.1s\n",
      "Epoch [65/130], Pixel: 0.0356, Percep: 0.1028, Color: 0.0163, Tiempo de época: 289.5s\n",
      "Epoch [66/130], Step [100/212], Loss_D: 0.3634, Loss_G: 0.2382, Pixel: 0.0422, Percep: 0.1063, Adv: 4.6976, Color: 0.0239, Tiempo iter: 86.9s\n",
      "Epoch [66/130], Step [200/212], Loss_D: 0.5014, Loss_G: 0.1902, Pixel: 0.0320, Percep: 0.0955, Adv: 2.7364, Color: 0.0166, Tiempo iter: 172.6s\n",
      "Epoch [66/130], Pixel: 0.0432, Percep: 0.1035, Color: 0.0208, Tiempo de época: 195.2s\n",
      "Epoch [67/130], Step [100/212], Loss_D: 0.2724, Loss_G: 0.2344, Pixel: 0.0405, Percep: 0.1188, Adv: 3.0691, Color: 0.0177, Tiempo iter: 223.9s\n",
      "Epoch [67/130], Step [200/212], Loss_D: 0.5004, Loss_G: 0.2369, Pixel: 0.0479, Percep: 0.1322, Adv: 0.5997, Color: 0.0241, Tiempo iter: 310.9s\n",
      "Epoch [67/130], Pixel: 0.0470, Percep: 0.1084, Color: 0.0211, Tiempo de época: 333.8s\n",
      "Epoch [68/130], Step [100/212], Loss_D: 0.3841, Loss_G: 0.2167, Pixel: 0.0497, Percep: 0.1096, Adv: 1.0231, Color: 0.0216, Tiempo iter: 87.1s\n",
      "Epoch [68/130], Step [200/212], Loss_D: 0.0526, Loss_G: 0.2045, Pixel: 0.0375, Percep: 0.0993, Adv: 2.8769, Color: 0.0165, Tiempo iter: 173.3s\n",
      "Epoch [68/130], Pixel: 0.0409, Percep: 0.1007, Color: 0.0183, Tiempo de época: 195.8s\n",
      "Epoch [69/130], Step [100/212], Loss_D: 0.2359, Loss_G: 0.2201, Pixel: 0.0414, Percep: 0.1079, Adv: 2.7969, Color: 0.0238, Tiempo iter: 87.0s\n",
      "Epoch [69/130], Step [200/212], Loss_D: 0.3926, Loss_G: 0.2296, Pixel: 0.0521, Percep: 0.1138, Adv: 1.4371, Color: 0.0199, Tiempo iter: 173.5s\n",
      "Epoch [69/130], Pixel: 0.0395, Percep: 0.1004, Color: 0.0181, Tiempo de época: 196.5s\n",
      "Epoch [70/130], Step [100/212], Loss_D: 1.1111, Loss_G: 0.2168, Pixel: 0.0215, Percep: 0.1148, Adv: 4.6487, Color: 0.0167, Tiempo iter: 141.9s\n",
      "Epoch [70/130], Step [200/212], Loss_D: 0.3416, Loss_G: 0.2050, Pixel: 0.0458, Percep: 0.0952, Adv: 2.1633, Color: 0.0199, Tiempo iter: 406.2s\n",
      "Epoch [70/130], Pixel: 0.0399, Percep: 0.1017, Color: 0.0185, Tiempo de época: 488.4s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 39\u001b[0m\n\u001b[1;32m     34\u001b[0m optimizer_D\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# 2. Actualizar Generador (G)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m fake_hr \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m pred_fake_for_G \u001b[38;5;241m=\u001b[39m discriminator(fake_hr)\n\u001b[1;32m     42\u001b[0m real_tensor_G \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(pred_fake_for_G, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/pateaAbuelitas/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pateaAbuelitas/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[5], line 70\u001b[0m, in \u001b[0;36mRRDBNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     69\u001b[0m     fea \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_first(x)\n\u001b[0;32m---> 70\u001b[0m     trunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrunk_conv(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrrdb_trunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfea\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     71\u001b[0m     fea \u001b[38;5;241m=\u001b[39m fea \u001b[38;5;241m+\u001b[39m trunk\n\u001b[1;32m     72\u001b[0m     fea \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsampling(fea)\n",
      "File \u001b[0;32m~/miniconda3/envs/pateaAbuelitas/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pateaAbuelitas/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/pateaAbuelitas/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/pateaAbuelitas/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pateaAbuelitas/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m, in \u001b[0;36mRRDB.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 30\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdb1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrdb2(out)\n\u001b[1;32m     32\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrdb3(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/pateaAbuelitas/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pateaAbuelitas/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m, in \u001b[0;36mResidualDenseBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(torch\u001b[38;5;241m.\u001b[39mcat([inputs, x1], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m     16\u001b[0m x3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(torch\u001b[38;5;241m.\u001b[39mcat([inputs, x1, x2], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n\u001b[0;32m---> 17\u001b[0m x4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv4(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx3\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     18\u001b[0m x5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv5(torch\u001b[38;5;241m.\u001b[39mcat([inputs, x1, x2, x3, x4], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs \u001b[38;5;241m+\u001b[39m x5 \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 130\n",
    "start_time = time.time() \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    epoch_start = time.time()  \n",
    "\n",
    "    #Ponerlos en modo entrenamiento\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    \n",
    "    for i, batch in enumerate(train_loader):\n",
    "\n",
    "        # Mover LR y HR a GPU\n",
    "        lr = batch[\"lr\"].to(device, non_blocking=True)\n",
    "        hr = batch[\"hr\"].to(device, non_blocking=True)\n",
    "        \n",
    "        #Generamos imagen fake\n",
    "        with torch.no_grad():\n",
    "            fake_hr = generator(lr)\n",
    "        \n",
    "        #Calculamos probabilidad de que sea real o fake\n",
    "        #==============Discriminador=========\n",
    "        pred_real = discriminator(hr)\n",
    "        pred_fake = discriminator(fake_hr.detach())\n",
    "        \n",
    "        real_tensor = torch.ones_like(pred_real, device=device) #Imagenes reales\n",
    "        fake_tensor = torch.zeros_like(pred_fake, device=device) #Imagenes falsas\n",
    "        \n",
    "        #Error del discriminador\n",
    "        loss_D_real = bce_loss(pred_real, real_tensor)\n",
    "        loss_D_fake = bce_loss(pred_fake, fake_tensor)\n",
    "        loss_D = 0.5 * (loss_D_real + loss_D_fake)\n",
    "        \n",
    "        #Actualizar pesos del Discriminador\n",
    "        optimizer_D.zero_grad()\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # ============Generador=============\n",
    "        fake_hr = generator(lr)\n",
    "\n",
    "        #Engañar a D haciéndole creer que fake_hr es real. Generar etiquetas de “unos” (real_tensor_G) y comparar con la predicción de D.\n",
    "        pred_fake_for_G = discriminator(fake_hr)\n",
    "        real_tensor_G = torch.ones_like(pred_fake_for_G, device=device)\n",
    "        loss_G_adv = bce_loss(pred_fake_for_G, real_tensor_G) #si D cree que fake_hr es real, loss_G_adv baja, haciendo que G genere más realistas\n",
    "        \n",
    "        #Perdida de pixel\n",
    "        loss_pixel = pixel_loss(fake_hr, hr)\n",
    "\n",
    "        #Perdida perceptual\n",
    "        feats_fake = vgg_extractor(fake_hr)[0]\n",
    "        feats_real = vgg_extractor(hr)[0]\n",
    "        loss_percep = perceptual_loss(feats_fake, feats_real)\n",
    "\n",
    "        #Pérdida de color\n",
    "        ycbcr_fake = rgb_to_ycbcr_batch(fake_hr)\n",
    "        ycbcr_real = rgb_to_ycbcr_batch(hr)\n",
    "        loss_cb   = F.l1_loss(ycbcr_fake[:, 1:2, :, :], ycbcr_real[:, 1:2, :, :])\n",
    "        loss_cr   = F.l1_loss(ycbcr_fake[:, 2:3, :, :], ycbcr_real[:, 2:3, :, :])\n",
    "        loss_color = loss_cb + loss_cr\n",
    "\n",
    "        #Parametros de penalizacion y relevancia\n",
    "        #lambda pizel con 1.5 significa que debe ser muy fiel a los pixeles\n",
    "        #lambda adv determina cuanto debe de engañar G a D, dependiendo de este, en las imagnees finales se pueden generar artefactos.\n",
    "        #Color asegura fidelidad en cuanto a color\n",
    "        \n",
    "        lambda_pixel = 1.5 #1 en un principio\n",
    "        lambda_percep = 1.2 #1 en un principip\n",
    "        lambda_adv = 0.01 #0.005 en un principio\n",
    "        lambda_color  = 0.02 #\n",
    "\n",
    "        #Perdida general\n",
    "        loss_G = lambda_pixel * loss_pixel + lambda_percep * loss_percep + lambda_adv * loss_G_adv + lambda_color  * loss_color\n",
    "\n",
    "        \n",
    "        #Actualizar pesos del generador\n",
    "        optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    #=======================Validacion en cada epoca\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        val_pixel_loss = 0.0\n",
    "        val_percep_loss = 0.0\n",
    "        val_color_loss  = 0.0\n",
    "        count = 0\n",
    "        \n",
    "        for batch_val in val_loader:\n",
    "            lr_val = batch_val[\"lr\"].to(device, non_blocking=True)\n",
    "            hr_val = batch_val[\"hr\"].to(device, non_blocking=True)\n",
    "            fake_hr_val = generator(lr_val)\n",
    "            \n",
    "            #perdida perceptual\n",
    "            val_pixel_loss += pixel_loss(fake_hr_val, hr_val).item()\n",
    "            feats_fake_val = vgg_extractor(fake_hr_val)[0]\n",
    "            feats_real_val = vgg_extractor(hr_val)[0]\n",
    "            val_percep_loss += perceptual_loss(feats_fake_val, feats_real_val).item()\n",
    "            \n",
    "            #Perdida de color\n",
    "            ycbcr_fake_val = rgb_to_ycbcr_batch(fake_hr_val)\n",
    "            ycbcr_real_val = rgb_to_ycbcr_batch(hr_val)\n",
    "            cb_l = F.l1_loss(ycbcr_fake_val[:, 1:2, :, :], ycbcr_real_val[:, 1:2, :, :])\n",
    "            cr_l = F.l1_loss(ycbcr_fake_val[:, 2:3, :, :], ycbcr_real_val[:, 2:3, :, :])\n",
    "            val_color_loss += (cb_l + cr_l).item()\n",
    "\n",
    "            count += 1\n",
    "        \n",
    "        val_pixel_loss /= count\n",
    "        val_percep_loss /= count\n",
    "        val_color_loss  /= count\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "            f\"Pixel: {val_pixel_loss:.4f}, \"\n",
    "            f\"Percep: {val_percep_loss:.4f}, \"\n",
    "            f\"Color: {val_color_loss:.4f}, \"\n",
    "            f\"Tiempo de época: {time.time() - epoch_start:.1f}s\"\n",
    "        )\n",
    "    \n",
    "    # ==============Guardar un Checkpoint ==============================\n",
    "    # Hubo como 3 ocasiones en que estaba lluviendo y se me fue la luz, interrumpiendo el entrenamiento.\n",
    "    #Pero pude recuperar el entrenamiento.\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'G_state_dict': generator.state_dict(),\n",
    "            'D_state_dict': discriminator.state_dict(),\n",
    "            'optimizer_G': optimizer_G.state_dict(),\n",
    "            'optimizer_D': optimizer_D.state_dict()\n",
    "        }\n",
    "        torch.save(checkpoint, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Entrenamiento completado en {total_time:.1f}s ({total_time/60:.1f} minutos).\")\n",
    "\n",
    "#Con un I511400H 6 nucleos 12 hilos y una rtx 3050 vram (laptop)\n",
    "#Tomó 5 minutos por cada epoca\n",
    "#Tomando un total de 12.5 horas de entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_71167/3581774095.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"checkpoint_epoch_70.pth\", map_location=device)\n"
     ]
    }
   ],
   "source": [
    "#Esto es solo para continuar entrenamiento a partir de un checkpoint, se me fue la luz en un momento y pude continuar\n",
    "#Se tienen que volver a correr todas las celdas anteriores al de arriba.\n",
    "\n",
    "\n",
    "checkpoint = torch.load(\"checkpoint_epoch_70.pth\", map_location=device)\n",
    "generator.load_state_dict(checkpoint[\"G_state_dict\"])\n",
    "discriminator.load_state_dict(checkpoint[\"D_state_dict\"])\n",
    "optimizer_G.load_state_dict(checkpoint[\"optimizer_G\"])\n",
    "optimizer_D.load_state_dict(checkpoint[\"optimizer_D\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/120], Step [100/212], Loss_D: 0.4058, Loss_G: 0.1766, Pixel: 0.0362, Percep: 0.0824, Adv: 2.3140, Color: 0.0172, Tiempo iter: 88.8s\n"
     ]
    }
   ],
   "source": [
    "#Entrenamiento para continuar a partir de una epoca.\n",
    "#Se puede generalizar para no repetir tanto codigo, pero ya no me dio tiempo\n",
    "\n",
    "\n",
    "start_epoch = checkpoint[\"epoch\"]\n",
    "num_epochs = 120\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs+1):\n",
    "    epoch_start = time.time()\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        lr = batch[\"lr\"].to(device, non_blocking=True)\n",
    "        hr = batch[\"hr\"].to(device, non_blocking=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            fake_hr = generator(lr)\n",
    "\n",
    "        pred_real = discriminator(hr)\n",
    "        pred_fake = discriminator(fake_hr.detach())\n",
    "\n",
    "        real_tensor = torch.ones_like(pred_real, device=device)\n",
    "        fake_tensor = torch.zeros_like(pred_fake, device=device)\n",
    "\n",
    "        loss_D_real = bce_loss(pred_real, real_tensor)\n",
    "        loss_D_fake = bce_loss(pred_fake, fake_tensor)\n",
    "        loss_D = 0.5 * (loss_D_real + loss_D_fake)\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        fake_hr = generator(lr)\n",
    "        pred_fake_for_G = discriminator(fake_hr)\n",
    "\n",
    "        real_tensor_G = torch.ones_like(pred_fake_for_G, device=device)\n",
    "        loss_G_adv = bce_loss(pred_fake_for_G, real_tensor_G)\n",
    "\n",
    "        loss_pixel = pixel_loss(fake_hr, hr)\n",
    "\n",
    "        feats_fake = vgg_extractor(fake_hr)[0]\n",
    "        feats_real = vgg_extractor(hr)[0]\n",
    "        loss_percep = perceptual_loss(feats_fake, feats_real)\n",
    "\n",
    "        ycbcr_fake = rgb_to_ycbcr_batch(fake_hr)\n",
    "        ycbcr_real = rgb_to_ycbcr_batch(hr)\n",
    "        loss_cb = F.l1_loss(ycbcr_fake[:, 1:2, :, :], ycbcr_real[:, 1:2, :, :])\n",
    "        loss_cr = F.l1_loss(ycbcr_fake[:, 2:3, :, :], ycbcr_real[:, 2:3, :, :])\n",
    "        loss_color = loss_cb + loss_cr\n",
    "\n",
    "        lambda_pixel = 1.5 #1 en un principio\n",
    "        lambda_percep = 1.2 #1 en un principip\n",
    "        lambda_adv = 0.01 #0.005 en un principio\n",
    "        lambda_color  = 0.02 #\n",
    "\n",
    "        loss_G = (\n",
    "            lambda_pixel * loss_pixel\n",
    "            + lambda_percep * loss_percep\n",
    "            + lambda_adv * loss_G_adv\n",
    "            + lambda_color * loss_color\n",
    "        )\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Imprimir métricas cada 100 iteraciones\n",
    "        if (i + 1) % 100 == 0:\n",
    "            elapsed_iter = time.time() - epoch_start\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{num_epochs}], Step [{i+1}/{len(train_loader)}], \"\n",
    "                f\"Loss_D: {loss_D.item():.4f}, Loss_G: {loss_G.item():.4f}, \"\n",
    "                f\"Pixel: {loss_pixel.item():.4f}, Percep: {loss_percep.item():.4f}, \"\n",
    "                f\"Adv: {loss_G_adv.item():.4f}, Color: {loss_color.item():.4f}, \"\n",
    "                f\"Tiempo iter: {elapsed_iter:.1f}s\"\n",
    "            )\n",
    "\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        val_pixel_loss = 0.0\n",
    "        val_percep_loss = 0.0\n",
    "        val_color_loss = 0.0\n",
    "        count = 0\n",
    "\n",
    "        for batch_val in val_loader:\n",
    "            lr_val = batch_val[\"lr\"].to(device, non_blocking=True)\n",
    "            hr_val = batch_val[\"hr\"].to(device, non_blocking=True)\n",
    "            fake_hr_val = generator(lr_val)\n",
    "\n",
    "            val_pixel_loss += pixel_loss(fake_hr_val, hr_val).item()\n",
    "\n",
    "            feats_fake_val = vgg_extractor(fake_hr_val)[0]\n",
    "            feats_real_val = vgg_extractor(hr_val)[0]\n",
    "            val_percep_loss += perceptual_loss(feats_fake_val, feats_real_val).item()\n",
    "\n",
    "            ycbcr_fake_val = rgb_to_ycbcr_batch(fake_hr_val)\n",
    "            ycbcr_real_val = rgb_to_ycbcr_batch(hr_val)\n",
    "            cb_l = F.l1_loss(ycbcr_fake_val[:, 1:2, :, :], ycbcr_real_val[:, 1:2, :, :])\n",
    "            cr_l = F.l1_loss(ycbcr_fake_val[:, 2:3, :, :], ycbcr_real_val[:, 2:3, :, :])\n",
    "            val_color_loss += (cb_l + cr_l).item()\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        val_pixel_loss /= count\n",
    "        val_percep_loss /= count\n",
    "        val_color_loss /= count\n",
    "\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        print(\n",
    "            f\"Epoch [{epoch}/{num_epochs}], Step [{i+1}/{len(train_loader)}], \"\n",
    "            f\"Loss_D: {loss_D.item():.4f}, Loss_G: {loss_G.item():.4f}, \"\n",
    "            f\"Pixel: {loss_pixel.item():.4f}, Percep: {loss_percep.item():.4f}, \"\n",
    "            f\"Adv: {loss_G_adv.item():.4f}, Color: {loss_color.item():.4f}, \"\n",
    "            f\"Tiempo: {elapsed_iter:.1f}s\"\n",
    "    \n",
    "        )\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        checkpoint = {\n",
    "            \"epoch\": epoch,\n",
    "            \"G_state_dict\": generator.state_dict(),\n",
    "            \"D_state_dict\": discriminator.state_dict(),\n",
    "            \"optimizer_G\": optimizer_G.state_dict(),\n",
    "            \"optimizer_D\": optimizer_D.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, f\"checkpoint_epoch_{epoch}.pth\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Entrenamiento completado en {total_time:.1f}s ({total_time/60:.1f} minutos).\")\n",
    "\n",
    "\n",
    "#Con un I511400H 6 nucleos 12 hilos y una rtx 3050 vram (laptop)\n",
    "#Tomó 5 minutos por cada epoca\n",
    "#Tomando un total de 12.5 horas de entrenamiento\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65913/1456583334.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load('checkpoint_epoch_70.pth', map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RRDBNet(\n",
       "  (conv_first): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (rrdb_trunk): Sequential(\n",
       "    (0): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (8): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (9): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (10): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (11): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (12): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (13): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (14): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (15): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (16): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (17): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (18): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (19): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (20): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (21): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (22): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trunk_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (upsampling): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): PixelShuffle(upscale_factor=2)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): PixelShuffle(upscale_factor=2)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (conv_last): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_out): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''EJECUTAR ESTO SOLO SI SE QUIERE APLICAR LA SUPER RESOLUCION A PARTIR DE UN CHECKPOINT'''\n",
    "ckpt = torch.load('checkpoint_epoch_70.pth', map_location=device)\n",
    "generator.load_state_dict(ckpt['G_state_dict'])\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def super_resolve_image(model,img_path,device,scale=4,tile_size=256,overlap=32):\n",
    "    \"\"\"\n",
    "    Aplica la super resolucion a partir de un modelo ya entrenado\n",
    "\n",
    "    Parametros:\n",
    "        model: El modelo RRDBNet Entrenado.\n",
    "        img_path: Direccion a la imagen que se le aplicará el escalado.\n",
    "        device: Se ocupara para realizar el trabajo (cpu o gpu).\n",
    "        scale: Factor de escalado, el modelo actual solo soporta 4 como input.\n",
    "        tile_size: Tamaño de cada mosaico que se procesa de manera independiente.\n",
    "        overlap: Longitud de cada mosaico para que se extienda sobre otro, sirve para evitar bordes visibles y tener una continuidad de texturas.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #Poner el modelo en modo evaluacion\n",
    "    model.eval()\n",
    "    lr_image = Image.open(img_path).convert(\"RGB\")\n",
    "    lr_np = np.array(lr_image).astype(np.float32) / 255.0  # Convertir en un array \n",
    "    h_lr, w_lr, _ = lr_np.shape #alto y largo\n",
    "    h_hr, w_hr = h_lr * scale, w_lr * scale  # Dimensiones de salida\n",
    "\n",
    "    # Arrays de output para acumular las sumas de piexeles y el overlapping\n",
    "    output_sum = np.zeros((h_hr, w_hr, 3), dtype=np.float32)\n",
    "    count_map = np.zeros((h_hr, w_hr, 3), dtype=np.float32)\n",
    "\n",
    "    # Function to process a tile\n",
    "    def process_tile(x0, y0, x1, y1):\n",
    "        '''\n",
    "        Recorta un mosaico de la imagen LR, lo procesa con el modelo y devuelve el\n",
    "        mosaico HR resultante como arreglo NumPy en [0,1].\n",
    "\n",
    "        Parametros:\n",
    "            x0, y0: Coordenadas de la esquina superior izquierda del mosaico en LR.\n",
    "            x1, y1: Coordenadas de la esquina inferior derecha del mosaico en LR.\n",
    "\n",
    "        '''\n",
    "        lr_tile = lr_np[y0:y1, x0:x1, :]\n",
    "        # Convierte a tensor con forma [1, 3, H, W]\n",
    "        lr_tensor = torch.from_numpy(lr_tile.transpose(2, 0, 1)).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            sr_tensor = model(lr_tensor)\n",
    "\n",
    "        # Convierte el tensor de salida a NumPy en (H*scale, W*scale, 3)\n",
    "        \n",
    "        sr_np = sr_tensor.squeeze(0).clamp(0, 1).cpu().numpy().transpose(1, 2, 0)\n",
    "        return sr_np\n",
    "\n",
    "    # La distancia que avanzamos en LR para cada mosaico\n",
    "    stride = tile_size - overlap\n",
    "    for y in range(0, h_lr, stride):\n",
    "        # Recorre coordenadas X de los mosaicos\n",
    "        for x in range(0, w_lr, stride):\n",
    "            # Determina bordes del mosaico, sin exceder los límites de la image\n",
    "            x_end = min(x + tile_size, w_lr)\n",
    "            y_end = min(y + tile_size, h_lr)\n",
    "            x0, y0 = x, y\n",
    "            x1, y1 = x_end, y_end\n",
    "\n",
    "         \n",
    "            sr_tile = process_tile(x0, y0, x1, y1)\n",
    "            # Calcular coordenadas en la version HR\n",
    "            x0_hr, y0_hr = x0 * scale, y0 * scale\n",
    "            x1_hr, y1_hr = x1 * scale, y1 * scale\n",
    "\n",
    "            # Acumula valores de píxeles y actualiza conteo para promediar luego\n",
    "            output_sum[y0_hr:y1_hr, x0_hr:x1_hr, :] += sr_tile\n",
    "            count_map[y0_hr:y1_hr, x0_hr:x1_hr, :] += 1.0\n",
    "\n",
    "    ## Promedia las zonas solapadas dividiendo suma entre conteo\n",
    "    output_avg = output_sum / count_map\n",
    "    # Convierte de nuevo a uint8 en [0,255]\n",
    "    output_img = (output_avg * 255.0).round().astype(np.uint8)\n",
    "    return Image.fromarray(output_img)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen escalada x4 guardada en: treeX4AhoraSi70.jpg\n"
     ]
    }
   ],
   "source": [
    "#Uso final\n",
    "#asegurarse que la imagen existe\n",
    "lr_input_path = \"./images/tree.jpg\"\n",
    "sr_output_path = \"treeX4AhoraSi70.jpg\"\n",
    "\n",
    "sr_image = super_resolve_image(\n",
    "    model=generator,\n",
    "    img_path=lr_input_path,\n",
    "    device=device,\n",
    "    scale=4,\n",
    "    tile_size=256,\n",
    "    overlap=32\n",
    ")\n",
    "\n",
    "sr_image.save(sr_output_path)\n",
    "print(f\"Imagen escalada x4 guardada en: {sr_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparacion de imagen original e imagen escalada\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "lr_display = Image.open(lr_input_path).convert(\"RGB\").resize(sr_image.size, Image.BICUBIC)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(lr_display)\n",
    "plt.title(\"Imagen original\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(sr_image)\n",
    "plt.title(\"Imagen escalada 4 veces\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f5f24377ab49a4a5c3fcb8652b63ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='Índice:', max=2649), Output()),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_image(idx)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_root = \"Flickr2K\"\n",
    "image_files = sorted([f for f in os.listdir(dataset_root) if f.endswith(\".png\")])\n",
    "\n",
    "# Función para mostrar la imagen dada la posición\n",
    "def show_image(idx):\n",
    "    img_path = os.path.join(dataset_root, image_files[idx])\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Imagen {idx + 1}/{len(image_files)}: {image_files[idx]}\")\n",
    "    plt.show()\n",
    "\n",
    "# Widget \n",
    "slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(image_files) - 1,\n",
    "    step=1,\n",
    "    description='Índice:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "widgets.interact(show_image, idx=slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://arxiv.org/pdf/1809.00219"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pateaAbuelitas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
